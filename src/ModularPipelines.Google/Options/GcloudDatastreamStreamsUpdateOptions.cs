// <auto-generated>
// This file was generated by ModularPipelines.OptionsGenerator on 2025-12-28.
// Source: https://cloud.google.com/sdk/gcloud/reference/datastream/streams/update
// Do not edit this file manually.
// </auto-generated>

#nullable enable

using System.Diagnostics.CodeAnalysis;
using ModularPipelines.Attributes;
using ModularPipelines.Google.Options;
using ModularPipelines.Models;

namespace ModularPipelines.Google.Options;

/// <summary>
/// updates a Datastream stream
/// </summary>
[ExcludeFromCodeCoverage]
[CliSubCommand("datastream", "streams", "update")]
public record GcloudDatastreamStreamsUpdateOptions : GcloudOptions
{
    /// <summary>
    /// Friendly name for the stream.
    /// </summary>
    [CliOption("--display-name", Format = OptionFormat.EqualsSeparated)]
    public string? DisplayName { get; set; }

    /// <summary>
    /// Path to a JSON file containing a list of rule sets to be applied to the     stream.       The JSON file is formatted as follows, with camelCase field naming:       [        {         "objectFilter": {          "sourceObjectIdentifier": {           "oracleIdentifier": {            "schema": "schema1",            "table": "table1"           }          }         },         "customizationRules": [          {           "bigqueryClustering": {            "columns": ["COL_A"]           }          }         ]        },        {         "objectFilter": {          "sourceObjectIdentifier": {           "oracleIdentifier": {            "schema": "schema2",            "table": "table2"           }          }         },         "customizationRules": [          {           "bigqueryPartitioning": {            "timeUnitPartition": {             "column": "TIME_COL",             "partitioningTimeGranularity": "PARTITIONING_TIME_GRANULARITY_DAY"            }           }          }         ]        }       ]
    /// </summary>
    [CliOption("--rule-sets", Format = OptionFormat.EqualsSeparated)]
    public string? RuleSets { get; set; }

    /// <summary>
    /// Stream state, can be set to: "RUNNING" or "PAUSED".
    /// </summary>
    [CliOption("--state", Format = OptionFormat.EqualsSeparated)]
    public string? State { get; set; }

    /// <summary>
    /// List of label KEY=VALUE pairs to update. If a label exists, its value     is modified. Otherwise, a new label is created.     Keys must start with a lowercase character and contain only hyphens     (-), underscores (_), lowercase characters, and numbers. Values must     contain only hyphens (-), underscores (_), lowercase characters, and     numbers.
    /// </summary>
    [CliOption("--update-labels", Format = OptionFormat.EqualsSeparated, AllowMultiple = true)]
    public KeyValue[]? UpdateLabels { get; set; }

    /// <summary>
    /// Used to specify the fields to be overwritten in the stream resource by     the update. If the update mask is used, then a field will be     overwritten only if it is in the mask. If the user does not provide a     mask then all fields will be overwritten. This is a comma-separated     list of fully qualified names of fields, written as snake_case or     camelCase. Example: "display_name, source_config.oracle_source_config".    At most one of these can be specified:     --backfill-none      Do not automatically backfill any objects. This flag is equivalent to      selecting the Manual backfill type in the Google Cloud console.     --backfill-all      Automatically backfill objects included in the stream source      configuration. Specific objects can be excluded. This flag is      equivalent to selecting the Automatic backfill type in the Google      Cloud console.     At most one of these can be specified:      --mongodb-excluded-objects=MONGODB_EXCLUDED_OBJECTS       Path to a YAML (or JSON) file containing the MongoDB data sources       to avoid backfilling.       The JSON file is formatted as follows, with camelCase field naming:          {           "databases": [            {             "database":"sample_database",             "collections": [              {               "collection": "sample_collection",               "fields": [                {                 "field": "sample_field",                }               ]              }             ]            }           ]          }      --mysql-excluded-objects=MYSQL_EXCLUDED_OBJECTS       Path to a YAML (or JSON) file containing the MySQL data sources to       avoid backfilling.       The JSON file is formatted as follows, with camelCase field naming:          {           "mysqlDatabases": [            {             "database":"sample_database",             "mysqlTables": [              {               "table": "sample_table",               "mysqlColumns": [                {                 "column": "sample_column",                }                ]              }             ]            }           ]          }      --oracle-excluded-objects=ORACLE_EXCLUDED_OBJECTS       Path to a YAML (or JSON) file containing the Oracle data sources to       avoid backfilling.       The JSON file is formatted as follows, with camelCase field naming:          {           "oracleSchemas": [            {             "schema": "SAMPLE",             "oracleTables": [              {               "table": "SAMPLE_TABLE",               "oracleColumns": [                {                 "column": "COL",                }               ]              }             ]            }           ]          }      --postgresql-excluded-objects=POSTGRESQL_EXCLUDED_OBJECTS       Path to a YAML (or JSON) file containing the PostgreSQL data       sources to avoid backfilling.       The JSON file is formatted as follows, with camelCase field naming:          {           "postgresqlSchemas": [            {             "schema": "SAMPLE",             "postgresqlTables": [              {               "table": "SAMPLE_TABLE",               "postgresqlColumns": [                {                 "column": "COL",                }               ]              }             ]            }           ]          }      --salesforce-excluded-objects=SALESFORCE_EXCLUDED_OBJECTS       Path to a YAML (or JSON) file containing the Salesforce data       sources to avoid backfilling.       The JSON file is formatted as follows, with camelCase field naming:          {           "objects": [            {             "objectName": "SAMPLE",            },            {             "objectName": "SAMPLE2",            }           ]          }      --sqlserver-excluded-objects=SQLSERVER_EXCLUDED_OBJECTS       Path to a YAML (or JSON) file containing the SQL Server data       sources to avoid backfilling.       The JSON file is formatted as follows, with camelCase field naming:          {           "schemas": [            {             "schema": "SAMPLE",             "tables": [              {               "table": "SAMPLE_TABLE",               "columns": [                {                 "column": "COL",                }               ]              }             ]            }           ]          }    At most one of these can be specified:     --clear-labels      Remove all labels. If --update-labels is also specified then      --clear-labels is applied first.      For example, to remove all labels:        $ gcloud datastream streams update --clear-labels      To remove all existing labels and create two new labels, foo and baz:        $ gcloud datastream streams update --clear-labels \         --update-labels foo=bar,baz=qux     --remove-labels=[KEY,...]      List of label keys to remove. If a label does not exist it is      silently ignored. If --update-labels is also specified then      --update-labels is applied first.    Connection profile resource - Resource ID of the destination connection   profile. This represents a Cloud resource. (NOTE) Some attributes are not   given arguments in this group but can be set in other ways.    To set the project attribute:    ◆ provide the argument --destination on the command line with a fully     specified name;    ◆ provide the argument --project on the command line;    ◆ set the property core/project.    To set the location attribute:    ◆ provide the argument --destination on the command line with a fully     specified name;    ◆ provide the argument --location on the command line.     --destination=DESTINATION      ID of the connection_profile or fully qualified identifier for the      connection_profile.      To set the connection_profile attribute:      ▸ provide the argument --destination on the command line.    At most one of these can be specified:     --bigquery-destination-config=BIGQUERY_DESTINATION_CONFIG      Path to a YAML (or JSON) file containing the configuration for Google      BigQuery Destination Config.      The YAML (or JSON) file should be formatted as follows:      BigQuery configuration with source hierarchy datasets and merge mode      (merge mode is by default):        {         "sourceHierarchyDatasets": {          "datasetTemplate": {           "location": "us-central1",           "datasetIdPrefix": "my_prefix",           "kmsKeyName": "projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{cryptoKey}"          }         },         "merge": {}         "dataFreshness": "3600s"        }      BigQuery configuration with source hierarchy datasets and append only      mode:       {         "sourceHierarchyDatasets": {          "datasetTemplate": {           "location": "us-central1",           "datasetIdPrefix": "my_prefix",           "kmsKeyName": "projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{cryptoKey}"          }         },         "appendOnly": {}        }      BigQuery configuration with single target dataset and merge mode:        {         "singleTargetDataset": {          "datasetId": "projectId:my_dataset"         },         "merge": {}         "dataFreshness": "3600s"        }      BigQuery configuration with Big Lake table configuration:       {         "singleTargetDataset": {          "datasetId": "projectId:datasetId"         },         "appendOnly": {},         "blmtConfig": {          "bucket": "bucketName",          "tableFormat": "ICEBERG",          "fileFormat": "PARQUET",          "connectionName": "projectId.region.connectionName",          "rootPath": "/root"         }        }     --gcs-destination-config=GCS_DESTINATION_CONFIG      Path to a YAML (or JSON) file containing the configuration for Google      Cloud Storage Destination Config.      The JSON file is formatted as follows:         {        "path": "some/path",        "fileRotationMb":5,        "fileRotationInterval":"15s",        "avroFileFormat": {}        }    At most one of these can be specified:     --force      Update the stream without validating it.     --validate-only      Only validate the stream, but do not update any resources. The      default is false.    Connection profile resource - Resource ID of the source connection   profile. This represents a Cloud resource. (NOTE) Some attributes are not   given arguments in this group but can be set in other ways.    To set the project attribute:    ◆ provide the argument --source on the command line with a fully     specified name;    ◆ provide the argument --project on the command line;    ◆ set the property core/project.    To set the location attribute:    ◆ provide the argument --source on the command line with a fully     specified name;    ◆ provide the argument --location on the command line.     --source=SOURCE      ID of the connection_profile or fully qualified identifier for the      connection_profile.      To set the connection_profile attribute:      ▸ provide the argument --source on the command line.    At most one of these can be specified:     --mongodb-source-config=MONGODB_SOURCE_CONFIG      Path to a YAML (or JSON) file containing the configuration for      MongoDB Source Config.      The JSON file is formatted as follows, with snake_case field naming:         {          "includeObjects": {},          "excludeObjects": {           "databases": [            {             "database": "sampleDb",             "collections": [              {               "collection": "sampleCollection",               "fields": [                {                 "field": "SAMPLE_FIELD",                }               ]              }             ]            }           ]          }         }     --mysql-source-config=MYSQL_SOURCE_CONFIG      Path to a YAML (or JSON) file containing the configuration for MySQL      Source Config.      The JSON file is formatted as follows, with camelCase field naming:         {          "includeObjects": {},          "excludeObjects": {           "mysqlDatabases": [             {              "database":"sample_database",              "mysqlTables": [               {                "table": "sample_table",                "mysqlColumns": [                 {                  "column": "sample_column",                 }                ]               }              ]             }            ]           }         }     --oracle-source-config=ORACLE_SOURCE_CONFIG      Path to a YAML (or JSON) file containing the configuration for Oracle      Source Config.      The JSON file is formatted as follows, with camelCase field naming:         {          "includeObjects": {},          "excludeObjects": {           "oracleSchemas": [            {             "schema": "SAMPLE",             "oracleTables": [              {               "table": "SAMPLE_TABLE",               "oracleColumns": [                {                 "column": "COL",                }               ]              }             ]            }           ]          }         }     --postgresql-source-config=POSTGRESQL_SOURCE_CONFIG      Path to a YAML (or JSON) file containing the configuration for      PostgreSQL Source Config.      The JSON file is formatted as follows, with camelCase field naming:         {          "includeObjects": {},          "excludeObjects": {           "postgresqlSchemas": [            {             "schema": "SAMPLE",             "postgresqlTables": [              {               "table": "SAMPLE_TABLE",               "postgresqlColumns": [                {                 "column": "COL",                }               ]              }             ]            }           ]          },          "replicationSlot": "SAMPLE_REPLICATION_SLOT",          "publication": "SAMPLE_PUBLICATION"         }     --salesforce-source-config=SALESFORCE_SOURCE_CONFIG      Path to a YAML (or JSON) file containing the configuration for      Salesforce Source Config.      The JSON file is formatted as follows, with camelCase field naming:         {          "pollingInterval": "3000s",          "includeObjects": {},          "excludeObjects": {           "objects": [            {             "objectName": "SAMPLE",             "fields": [              {               "fieldName": "SAMPLE_FIELD",              }             ]            }           ]          }         }     --sqlserver-source-config=SQLSERVER_SOURCE_CONFIG      Path to a YAML (or JSON) file containing the configuration for SQL      Server Source Config.      The JSON file is formatted as follows, with camelCase field naming:         {          "includeObjects": {},          "excludeObjects": {           "schemas": [            {             "schema": "SAMPLE",             "tables": [              {               "table": "SAMPLE_TABLE",               "columns": [                {                 "column": "COL",                }               ]              }             ]            }           ]          },          "maxConcurrentCdcTasks": 2,          "maxConcurrentBackfillTasks": 10,          "transactionLogs": {} # Or changeTables         }
    /// </summary>
    [CliOption("--update-mask", Format = OptionFormat.EqualsSeparated)]
    public string? UpdateMask { get; set; }

}
